{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Overview \n",
    "\n",
    "We will establish the state space, or we can think of this as the environment in which the agent will be trained. When an agent is in a state, it chooses an action based on a policy. There are 2 ways to set up policies:\n",
    "+ Deterministic: in each state, the value of the actions is specifically defined.\n",
    "+ Stochastic: in each state, the values of the action and state form a probability space.\n",
    "\n",
    "In this example, we will use a stochastic policy setting. At each state, the search space for the action will be evaluated according to a random function, we will take the largest value in that range to choose the behavior.\n",
    "\n",
    "Note: in this example, the main purpose is to describe the definitions in the environment and agent settings in reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states = 4\n",
    "\n",
    "env = np.arange(n_states*n_states).reshape((n_states, n_states))\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.88512545e-01, 5.04723572e-02, 6.88635612e-01, 1.13468092e-01],\n",
       "       [4.66650790e-01, 3.75943251e-01, 8.02153806e-01, 1.83048417e-03],\n",
       "       [2.84353645e-01, 1.56413561e-01, 9.05563521e-01, 1.52588051e-01],\n",
       "       [9.00961976e-01, 2.29482913e-02, 5.84795892e-01, 6.08760774e-01],\n",
       "       [6.70263356e-01, 3.65002120e-01, 7.44248083e-01, 9.60752867e-02],\n",
       "       [4.76326444e-01, 7.19372667e-01, 2.48577860e-01, 9.22846364e-01],\n",
       "       [3.92032337e-01, 6.02519282e-01, 6.61365720e-02, 3.55197051e-01],\n",
       "       [3.39350144e-01, 6.23478301e-01, 9.41235240e-01, 8.76513264e-01],\n",
       "       [3.07007145e-01, 8.22162412e-01, 7.11326359e-02, 9.85156894e-01],\n",
       "       [5.50355598e-01, 3.50294427e-01, 8.93996375e-01, 7.52576175e-01],\n",
       "       [9.67988060e-01, 7.97985860e-01, 6.78714784e-01, 4.14907995e-01],\n",
       "       [5.00140475e-01, 4.37461898e-01, 1.25538741e-01, 7.20044004e-01],\n",
       "       [4.78090936e-01, 8.30538694e-01, 3.71353344e-01, 4.91637277e-01],\n",
       "       [9.52811646e-02, 9.79271311e-01, 6.69445337e-02, 7.53383864e-01],\n",
       "       [1.19151940e-05, 3.21058853e-01, 4.20917757e-01, 6.49230468e-03],\n",
       "       [2.47958008e-01, 8.05567214e-01, 1.56714963e-03, 7.12833298e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions = 4\n",
    "q_table_old = np.random.rand(n_states**2, n_actions) # The reason for square the n_states is although we initalize 4 n_states, but in our env, there is actually 16 states. \n",
    "q_table_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.88512545e-01, 5.04723572e-02, 1.18744733e+00, 1.13468092e-01],\n",
       "       [4.66650790e-01, 3.75943251e-01, 4.68621165e+00, 1.83048417e-03],\n",
       "       [2.84353645e-01, 1.56413561e-01, 8.19310149e+00, 1.52588051e-01],\n",
       "       [9.99583245e+00, 2.29482913e-02, 5.84795892e-01, 6.08760774e-01],\n",
       "       [6.70263356e-01, 3.65002120e-01, 1.13848234e+00, 9.60752867e-02],\n",
       "       [4.76326444e-01, 7.19372667e-01, 2.48577860e-01, 5.47486095e+00],\n",
       "       [3.92032337e-01, 7.56620376e+00, 6.61365720e-02, 3.55197051e-01],\n",
       "       [3.39350144e-01, 6.23478301e-01, 1.17617547e+01, 8.76513264e-01],\n",
       "       [3.07007145e-01, 8.22162412e-01, 7.11326359e-02, 1.82140476e+00],\n",
       "       [5.50355598e-01, 3.50294427e-01, 4.60411516e+00, 7.52576175e-01],\n",
       "       [6.33529114e+00, 7.97985860e-01, 6.78714784e-01, 4.14907995e-01],\n",
       "       [5.00140475e-01, 4.37461898e-01, 1.25538741e-01, 1.28594352e+01],\n",
       "       [4.78090936e-01, 1.61328618e-01, 3.71353344e-01, 4.91637277e-01],\n",
       "       [9.52811646e-02, 3.62244408e+00, 6.69445337e-02, 7.53383864e-01],\n",
       "       [1.19151940e-05, 3.21058853e-01, 8.62842412e+00, 6.49230468e-03],\n",
       "       [2.47958008e-01, 8.05567214e-01, 1.56714963e-03, 7.12833298e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = 0\n",
    "discount_factor = 0.01\n",
    "learning_rate = 0.9\n",
    "\n",
    "q_table = deepcopy(q_table_old)\n",
    "action_space = []\n",
    "\n",
    "while True: \n",
    "    # To make sure that when the next state is bounded\n",
    "    if state + 1 >= n_states*n_states: \n",
    "        break\n",
    "\n",
    "    # From the current state, we would choose the action that has the highest score\n",
    "    action_from_state = q_table[state]\n",
    "    action = np.argmax(action_from_state)\n",
    "    action_space.append(action)\n",
    "    currrent_q_value = q_table[state, action]\n",
    "    reward = env[state % (n_states), action] # We take modulo from state because we want to point to the row where the state at. \n",
    "    next_action = np.max(q_table[state+1])\n",
    "    target_q_value = reward + discount_factor*next_action\n",
    "\n",
    "    q_table[state, action] = learning_rate* (target_q_value - currrent_q_value)\n",
    "\n",
    "    state+= 1\n",
    "\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.49881172,  0.        ],\n",
       "       [ 0.        ,  0.        ,  3.88405784,  0.        ],\n",
       "       [ 0.        ,  0.        ,  7.28753797,  0.        ],\n",
       "       [ 9.09487048,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.39423426,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  4.55201458],\n",
       "       [ 0.        ,  6.96368448,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , 10.82051946,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.83624787],\n",
       "       [ 0.        ,  0.        ,  3.71011878,  0.        ],\n",
       "       [ 5.36730308,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , 12.13939124],\n",
       "       [ 0.        , -0.66921008,  0.        ,  0.        ],\n",
       "       [ 0.        ,  2.64317277,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  8.20750637,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table - q_table_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 0, 2, 3, 1, 2, 3, 2, 0, 3, 1, 1, 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "small_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
